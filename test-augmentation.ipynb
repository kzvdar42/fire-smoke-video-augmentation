{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ffmpeg_utils\n",
    "from augment_script import process_video, process_images, create_folder\n",
    "from augment import Augmentations\n",
    "from reader import VideoEffectReader, ImageEffectReader\n",
    "from writer import COCO_writer\n",
    "from bbox_utils import get_scale_ratio, resize_by_max_side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_type = 'fire'\n",
    "e_type = 'smoke'\n",
    "e_type = 'real_fire_smoke'\n",
    "\n",
    "def get_effect_paths(e_type):\n",
    "    assert e_type in ['fire', 'smoke', 'real_fire_smoke'], 'Unsupported'\n",
    "    raw_png_effects_path  = f'effects/raw_{e_type}_images'\n",
    "    prep_png_effects_path = f'effects/prep_{e_type}_images'\n",
    "    raw_mov_effects_path  = f'effects/raw_{e_type}_vid'\n",
    "    prep_mov_effects_path = f'effects/prep_{e_type}_vid'\n",
    "    return (raw_png_effects_path, prep_png_effects_path,\n",
    "            raw_mov_effects_path, prep_mov_effects_path)\n",
    "\n",
    "(raw_png_effects_path, prep_png_effects_path,\n",
    " raw_mov_effects_path, prep_mov_effects_path) = get_effect_paths(e_type)\n",
    "\n",
    "\n",
    "vid_out_path = 'output/out.mp4'\n",
    "annot_out_path = 'output/annotations/instances_default.json'\n",
    "\n",
    "# Create folders\n",
    "# for path in [raw_png_effects_path, prep_png_effects_path,\n",
    "#              raw_mov_effects_path, prep_mov_effects_path,\n",
    "#              os.path.split(vid_out_path)[0],\n",
    "#              os.path.split(annot_out_path)[0]]:\n",
    "#     os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and trim empty pixels\n",
    "raw_png_effects_path = 'effects/non_funny'\n",
    "prep_png_effects_path = 'effects/prep_non_funny'\n",
    "e_type = 'non-funny'\n",
    "# for i, effect_path in enumerate(glob(os.path.join(raw_png_effects_path, '*.png'))):\n",
    "#     e_img = cv2.imread(effect_path, cv2.IMREAD_UNCHANGED)\n",
    "#     # Trim empty pixels\n",
    "#     y, x = e_img[:, :, 3].nonzero()\n",
    "#     minx, miny = np.min(x), np.min(y)\n",
    "#     maxx, maxy = np.max(x), np.max(y)\n",
    "#     e_img = e_img[miny:maxy, minx:maxx]\n",
    "#     # Resize to 512px\n",
    "#     scale_ratio = get_scale_ratio(e_img, 512)\n",
    "#     e_img = resize_by_max_side(e_img, scale_ratio)\n",
    "#     os.makedirs(prep_png_effects_path, exist_ok=True)\n",
    "#     cv2.imwrite(os.path.join(prep_png_effects_path, f'{e_type}-{i}.png'), e_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename videos\n",
    "# for i, mov_path in enumerate(glob(os.path.join(raw_mov_effects_path, '*.mov'))):\n",
    "#     print(mov_path)\n",
    "#     path = os.path.split(mov_path)[0]\n",
    "#     os.rename(mov_path, os.path.join(path, f'{e_type}-{i}.mov'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and extract alpha videos\n",
    "rewrite = False\n",
    "# for input_path in glob(os.path.join(raw_mov_effects_path, '*.mov')):\n",
    "#     input_path = os.path.abspath(input_path)\n",
    "#     filename = os.path.splitext(os.path.split(input_path)[1])[0]\n",
    "#     out_path = os.path.join(prep_mov_effects_path, filename + '.webm')\n",
    "#     out_path = os.path.abspath(out_path)\n",
    "#     ffmpeg_utils.convert_mov2webm(input_path, out_path, y=rewrite)\n",
    "#     ffmpeg_utils.extract_alpha(out_path, y=rewrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e_paths = get_effect_paths('fire')\n",
    "e_paths = get_effect_paths('real_fire_smoke')\n",
    "prep_e_png_fire_path, prep_e_mov_fire_path = e_paths[1], e_paths[3]\n",
    "e_paths = get_effect_paths('smoke')\n",
    "prep_e_png_smoke_path, prep_e_mov_smoke_path = e_paths[1], e_paths[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prep_e_png_fire_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7ca5999f0751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0me_png_fire\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_e_png_fire_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0me_png_fire\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'effects/animals/retrieved'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0me_mov_fire\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_e_mov_fire_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.webm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0me_png_smoke\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_e_png_smoke_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0me_mov_smoke\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_e_mov_smoke_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.webm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prep_e_png_fire_path' is not defined"
     ]
    }
   ],
   "source": [
    "e_png_fire = glob(os.path.join(prep_e_png_fire_path, '*.png'))\n",
    "e_png_fire = glob(os.path.join('effects/animals/retrieved', '*.png'))\n",
    "e_mov_fire = glob(os.path.join(prep_e_mov_fire_path, '*.webm'))\n",
    "e_png_smoke = glob(os.path.join(prep_e_png_smoke_path, '*.png'))\n",
    "e_mov_smoke = glob(os.path.join(prep_e_mov_smoke_path, '*.webm'))\n",
    "e_png_fire[:15], e_mov_fire[:15], e_png_smoke[:15], e_mov_smoke[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['source_videos\\\\2020-06-23_16-40-40.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_09_58_11.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_09_58_50.ts.mp4',\n",
       " 'source_videos\\\\ufa']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_videos = glob('source_videos/*')\n",
    "source_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'e_png_fire' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d8b06080580c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m e_readers = [\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#     VideoEffectReader(e_mov_fire[1:2]),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mImageEffectReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me_png_fire\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coco'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m ]\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'e_png_fire' is not defined"
     ]
    }
   ],
   "source": [
    "# COCO_writer\n",
    "coco_writer = COCO_writer([\n",
    "    {\n",
    "        'name': 'Fire',\n",
    "        'supercategory': '',\n",
    "        'id': 2,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Smoke',\n",
    "        'supercategory': '',\n",
    "        'id': 4,\n",
    "    },\n",
    "])\n",
    "\n",
    "e_readers = [\n",
    "#     VideoEffectReader(e_mov_fire[1:2]),\n",
    "    ImageEffectReader(e_png_fire, annot_type='coco', preload=False),\n",
    "]\n",
    "\n",
    "\n",
    "# Augmentations\n",
    "fire_augment = Augmentations(\n",
    "    e_readers,\n",
    "    config_path='augment_config.yaml',\n",
    "    mov_min_size= 300,\n",
    "    mov_max_size= 900,\n",
    "    do_resize=True,\n",
    "    do_flip=True,\n",
    "    do_rotate=True,\n",
    "    do_brightness=True,\n",
    "    do_gamma=True,\n",
    "    do_blur=True,\n",
    "    blur_radius=11,\n",
    "    contour_radius=10,\n",
    "    debug_level=2,\n",
    "    min_n_objects=10,\n",
    "    max_n_objects=10,\n",
    "    use_alpha=True,\n",
    "    min_transparency=100,\n",
    "    max_transparency=100,\n",
    "    ck_start=1,\n",
    "    ck_range=10,\n",
    "    min_duration=1,\n",
    "    max_duration=2,\n",
    ")\n",
    "\n",
    "# smoke_augment = Augmentations(\n",
    "#     e_png_smoke,\n",
    "#     e_mov_smoke,\n",
    "#     config_path='augment_config.yaml',\n",
    "#     do_resize=True,\n",
    "#     do_flip=True,\n",
    "#     do_rotate=False,\n",
    "#     do_contrast=False,\n",
    "#     debug_level=2,\n",
    "#     ck_start=2,\n",
    "#     ck_range=15,\n",
    "#     max_n_objects=3,\n",
    "#     use_alpha=True\n",
    "# )\n",
    "\n",
    "augmentations = [\n",
    "    fire_augment,\n",
    "#     smoke_augment\n",
    "]\n",
    "\n",
    "# process_video(source_videos[0], augmentations, vid_out_path, coco_writer, show_debug=True)\n",
    "\n",
    "# # Write annotations.\n",
    "# os.makedirs(os.path.split(annot_out_path)[0], exist_ok=True)\n",
    "# coco_writer.write_result(annot_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                           | 184/15004 [01:36<2:09:26,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "process_video(source_videos[0], augmentations, vid_out_path, coco_writer, show_debug=True, write_debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_fire/annotations/smoke.json\n"
     ]
    }
   ],
   "source": [
    "# Fix for `id=0` for all annotations\n",
    "for path in glob('new_fire/annotations/smoke.json'):\n",
    "    print(path)\n",
    "    with open(path) as in_file:\n",
    "        j = json.load(in_file)\n",
    "    for i, annot in enumerate(j['annotations']):\n",
    "        annot['id'] = i\n",
    "        j['annotations'][i] = annot\n",
    "    \n",
    "    with open(path, 'w') as out_file:\n",
    "        out_file.write(json.dumps(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "import torch\n",
    "\n",
    "net = ptcv_get_model(\"squeezenet_v1_1\", pretrained=True).cuda()\n",
    "# net = ptcv_get_model(\"mobilenetv3_large_w1\", pretrained=True).cuda()\n",
    "# net = ptcv_get_model(\"efficientnet_b4b\", pretrained=True).cuda()\n",
    "# net = ptcv_get_model(\"squeezenet_v1_0\", pretrained=True)\n",
    "# net = ptcv_get_model(\"shufflenet_g1_w1\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5209f4f6ba46249fea93b482921671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19267.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bbox_utils import convert_xywh_xyxy, convert_xyxy_xywh, blur_contour\n",
    "import math\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "# animals_coco = COCO('effects/animals/animals.json')\n",
    "writer = COCO_writer(animals_coco.dataset['categories'])\n",
    "\n",
    "create_folder('effects/animals/retrieved', clean_out=True)\n",
    "\n",
    "is_exit = False\n",
    "pbar = tqdm(total=len(animals_coco.imgs))\n",
    "for img_id, img_info in animals_coco.imgs.items():\n",
    "    read_img_name = os.path.split(img_info['image'])[1]\n",
    "    path = 'effects/animals/animals/' + read_img_name\n",
    "    image = cv2.imread(path)\n",
    "    ann_ids = animals_coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "    for obj in animals_coco.loadAnns(ann_ids):\n",
    "        if obj['area'] < 3000:\n",
    "            continue\n",
    "        if len(obj['segmentation']) > 1:\n",
    "            continue\n",
    "        mask = np.zeros((*image.shape[:2], 1), dtype=np.uint8)\n",
    "        segments = []\n",
    "        for segment in obj['segmentation'][:1]:\n",
    "            segment = np.array(segment).reshape(-1, 1, 2).astype(np.int32)\n",
    "            segments.append(segment)\n",
    "        segments = np.array(segments).reshape(-1, 1, 2)\n",
    "        cv2.fillPoly(mask, [segments], (255))\n",
    "        img = image.copy()\n",
    "        img = np.concatenate((img, mask), -1)\n",
    "        img = blur_contour(img, blur_radius=21, contour_radius=15, blur_image=False)\n",
    "        \n",
    "        y, x = img[:, :, 3].nonzero()\n",
    "        minx, miny = np.min(x), np.min(y)\n",
    "        maxx, maxy = np.max(x), np.max(y)\n",
    "        img = img[miny:maxy, minx:maxx]\n",
    "        out_img = img.copy()\n",
    "        img, mask = img[:, :, :3].copy(), img[:, :, 3:].copy()\n",
    "        \n",
    "        # -------------------- Classification\n",
    "        mean_rgb = (0.485, 0.456, 0.406)\n",
    "        std_rgb = (0.229, 0.224, 0.225)\n",
    "#         x = image\n",
    "        x = img #(img * (mask / 255)).astype(np.uint8)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "        x = cv2.resize(x, (224, 224))\n",
    "        # Convert image to a float tensor and normalize it:\n",
    "        model_image = x.copy()\n",
    "        x = x.astype(np.float32)\n",
    "        x = x / 255.0\n",
    "        x = (x - np.array(mean_rgb)) / np.array(std_rgb)\n",
    "        x = x.transpose(2, 0, 1)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = torch.Tensor(x)\n",
    "        y = net(x.cuda()).detach().cpu()\n",
    "        y = torch.nn.Softmax(dim=-1)(y)\n",
    "        predicted = torch.argsort(y[0], descending=True)[:5]\n",
    "        predicted = [yi.item() for yi in predicted[predicted > 0.05]]\n",
    "        if not good_classes.intersection(predicted):\n",
    "            continue\n",
    "        new_img_id, filename = writer.add_frame(*img.shape[:2], file_ext='png')\n",
    "        track_id = new_img_id\n",
    "        category_id = writer.get_cat_id(animals_coco.cats[obj['category_id']]['name'])\n",
    "        cv2.imwrite(f'effects/animals/retrieved/{filename}', out_img)\n",
    "        pbar.set_description(f'Processed {new_img_id}')\n",
    "        \n",
    "        if len(segments.shape) > 3:\n",
    "            print('OH, NO!')\n",
    "            print(segments.shape)\n",
    "        segments = np.array(segments).reshape(-1, 1, 2) - (minx, miny)\n",
    "        h, w = img.shape[:2]\n",
    "        segments[:, :, 0] = np.clip(segments[:, :, 0], 0, w - 1)\n",
    "        segments[:, :, 1] = np.clip(segments[:, :, 1], 0, h - 1)\n",
    "        bbox = cv2.boundingRect(segments.astype(np.int32))\n",
    "        writer.add_annotation(new_img_id, bbox, track_id, category_id, segments)\n",
    "        if new_img_id % 500 == 0:\n",
    "            writer.write_result('effects/animals/retrieved.json')\n",
    "#         bbox = convert_xywh_xyxy(bbox, *img.shape[:2][::-1])\n",
    "#         cv2.rectangle(img, tuple(bbox[:2]), tuple(bbox[2:4]), (22, 48, 163), 2)\n",
    "#         for segment in segments:\n",
    "#             cv2.drawContours(img, segments, -1, (0, 0, 255), 4)\n",
    "#         cv2.imshow('orig_image', image)\n",
    "#         cv2.imshow('model_image', model_image)\n",
    "#         cv2.imshow('img', (img * (mask / 255)).astype(np.uint8))\n",
    "#         cv2.imshow('mask', mask)\n",
    "#         key = cv2.waitKey(0) & 0xFF\n",
    "#         if key == ord('q'):\n",
    "#             print('Exit!')\n",
    "#             is_exit = True\n",
    "#             break\n",
    "#     if is_exit:\n",
    "#         break\n",
    "    pbar.update(1)\n",
    "cv2.destroyAllWindows()\n",
    "writer.write_result('effects/animals/retrieved.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatworm, platyhelminth\n",
      "nematode, nematode worm, roundworm\n",
      "Italian greyhound\n",
      "Labrador retriever\n",
      "Doberman, Doberman pinscher\n",
      "miniature pinscher\n",
      "Great Dane\n",
      "dalmatian, coach dog, carriage dog\n",
      "buckle\n",
      "chain\n",
      "corkscrew, bottle screw\n",
      "cornet, horn, trumpet, trump\n",
      "electric guitar\n",
      "flute, transverse flute\n",
      "microphone, mike\n",
      "sax, saxophone\n",
      "chocolate sauce, chocolate syrup\n",
      "cup\n"
     ]
    }
   ],
   "source": [
    "for idx in (y[0] > 0.01).nonzero():\n",
    "    idx = idx.item()\n",
    "#     idx = (y[0] == yi).nonzero().item()\n",
    "    print(classes[str(idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(10, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(10, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(9, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(9, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(13, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(21, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(8, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(18, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(20, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(13, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(10, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(13, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(5, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(2, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(2, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(2, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(5, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(2, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(9, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(2, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(1, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(1, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(2, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(4, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(2, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-a6cd56af13a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'e_frame'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "effect_path = 'effects/prep_real_fire_smoke_vid/fire-3'\n",
    "cap = cv2.VideoCapture(f'{effect_path}.webm')\n",
    "alpha_cap = cv2.VideoCapture(f'{effect_path}_alpha.mp4')\n",
    "while True:\n",
    "    ret, e_frame = cap.read()\n",
    "    a_ret, e_alpha = alpha_cap.read()\n",
    "    init_e_alpha = e_alpha.copy()\n",
    "    if not ret or not a_ret:\n",
    "        print(ret, a_ret)\n",
    "        break\n",
    "#     rgb_sum = np.expand_dims(np.sum(e_alpha, axis=2), -1)\n",
    "#     e_alpha = np.clip(rgb_sum, 0, 255, dtype=np.uint8)\n",
    "    e_alpha = e_alpha[:, :, :1]\n",
    "    print(e_alpha.shape)\n",
    "    e_mask = np.ones(e_alpha.shape, dtype=np.uint8) * 255\n",
    "    e_frame = np.concatenate((e_frame, e_alpha), axis=2)\n",
    "    # Blur\n",
    "    blur_radius = 11\n",
    "    contour_radius = 5\n",
    "    image, alpha = e_frame[:, :, :3].copy(), e_frame[:, :, 3:].copy()\n",
    "\n",
    "    contours, _ = cv2.findContours(alpha.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(contours[0].shape, contours[0].dtype)\n",
    "    cv2.boundingRect(contours[0])\n",
    "    \n",
    "    b_rad = (blur_radius, blur_radius)\n",
    "    blurred_img = image#cv2.GaussianBlur(image, b_rad, 0)\n",
    "    alpha[:, :, 0] = cv2.GaussianBlur(alpha, b_rad, 0)\n",
    "\n",
    "    mask = np.zeros((*image.shape[:2], 1), np.ubyte)\n",
    "    cv2.drawContours(mask, contours, -1, (1), contour_radius)\n",
    "    output = np.where(mask, blurred_img, image)\n",
    "    print((alpha / 255).max(), np.median(alpha / 255))\n",
    "    print(output.max())\n",
    "    output[...] = output * (alpha / 255)\n",
    "    print(output.max())\n",
    "    cv2.imshow('alpha', init_e_alpha)\n",
    "    cv2.imshow('mask', mask * 255)\n",
    "    cv2.imshow('output', output)\n",
    "    cv2.imshow('e_frame', e_frame)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augment import Augmentations\n",
    "from augment_script import _process_image\n",
    "from bbox_utils import (convert_xywh_xyxy, convert_xyxy_xywh,\n",
    "                        resize, rotate, flip, gamma_correction,\n",
    "                        blur_contour)\n",
    "\n",
    "augment = Augmentations.augment\n",
    "merge_images = Augmentations.merge_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f blur_contour process_video(source_videos[0], augmentations, vid_out_path, coco_writer, show_debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob(os.path.join('ufa/images', f'*.jpg'))\n",
    "out_path = 'output/test'\n",
    "show_debug, write_debug = False, False\n",
    "%lprun -f process_images process_images(images, augmentations, out_path, coco_writer, show_debug, write_debug, n_workers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5922650026558175 0.9899783176964153 0.8003302973044949\n",
      "-9.670270866233837 8.323729912185293 -0.022608726770813894\n"
     ]
    }
   ],
   "source": [
    "a = np.random.normal(loc=0.8, scale=0.05, size=10000)\n",
    "b = np.random.normal(loc=0, scale=2.5, size=10000)\n",
    "print(a.min(), a.max(), a.mean())\n",
    "print(b.min(), b.max(), b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually adding effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import json\n",
    "from itertools import cycle\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ffmpeg_utils\n",
    "from augment_script import process_video, process_images, create_folder, draw_debug, VideoEffectReader, get_coco_writer\n",
    "from augment import Effect, Augmentations, AugmentationConfig\n",
    "from reader import VideoEffectReader, ImageEffectReader\n",
    "from writer import COCO_writer\n",
    "from bbox_utils import (convert_xywh_xyxy, convert_xyxy_xywh,\n",
    "                        blur_contour, resize, rotate, flip,\n",
    "                        get_scale_ratio, resize_by_max_side,\n",
    "                        gamma_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_effect(reader_id, idx, track_id, angle=0, gain=1, bias=0, gamma=1, size=800, duration=None, offset=None):\n",
    "    duration = duration if duration is not None else 30 * 3\n",
    "    offset = offset if offset is not None else (700, 700)\n",
    "    return Effect(\n",
    "    reader_id = reader_id,\n",
    "    idx = idx,\n",
    "    track_id = track_id,\n",
    "    size = size,\n",
    "    offset = offset,\n",
    "    angle = angle,\n",
    "    is_flip = False,\n",
    "    transparency = 100 / 100, \n",
    "    gain = gain,\n",
    "    bias = bias,\n",
    "    gamma = gamma,\n",
    "    duration = duration,\n",
    "    cur_dur = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aug_new:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.gains = [g for g in np.linspace(1, 1.6, 3)]\n",
    "        self.biases = [b for b in np.linspace(0, 20, 2)]\n",
    "        self.gammas = [g for g in np.linspace(0.4, 1.5, 3)]\n",
    "        \n",
    "        self.sizes = [s for s in np.linspace(50, 300, 4)]        \n",
    "        self.sizes = [20,30, 40, 50, 70, 100, 120, 150, 200]\n",
    "        \n",
    "        self.n_line = 4\n",
    "        self.y_pos = 500\n",
    "        self.x_poses = cycle([int(x_pos) for x_pos in np.linspace(150, 1550, self.n_line)])\n",
    "        self.x_poses = cycle([700])\n",
    "        self.idxs = cycle([*range(84)])\n",
    "    \n",
    "    def get_iter(self):\n",
    "        reader_id, idx = 0, 0\n",
    "        effects = []\n",
    "        for bias in self.biases:\n",
    "            for gain in self.gains:\n",
    "                for gamma in self.gammas:\n",
    "                    for size in self.sizes:\n",
    "                        track_id = 0\n",
    "                        effects.append(make_effect(reader_id, next(self.idxs), track_id,\n",
    "                                                   gain=gain, bias=bias, gamma=gamma,\n",
    "                                                   offset=(next(self.x_poses), self.y_pos),\n",
    "                                                   size=size, duration=5))\n",
    "                        if len(effects) >= self.n_line:\n",
    "                            yield effects\n",
    "                            effects = []\n",
    "        if len(effects):\n",
    "            yield effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([*aug_new().get_iter()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_box_sizes(effect_path, size):\n",
    "    e_reader = VideoEffectReader([effect_path], use_alpha=True)\n",
    "    e_info = make_effect(0, 0, 0, size=size)\n",
    "    min_sizes, max_sizes = [], []\n",
    "    while(True):\n",
    "        frame, segments, e_cats = e_reader.get_frame(e_info, read_annot=True)\n",
    "        e_info.cur_dur += 1\n",
    "        segments = np.array([np.array(segment, dtype=np.float32) for segment in segments], dtype=object) if segments else None\n",
    "        if frame is None:\n",
    "            break\n",
    "        if segments is not None:\n",
    "            frame, _, segments = resize(frame, e_info.size, segments=segments)\n",
    "            for poly in segments:\n",
    "                bbox = cv2.boundingRect(poly.astype(np.int32))\n",
    "                min_sizes.append(min(bbox[2:]))\n",
    "                max_sizes.append(max(bbox[2:]))\n",
    "    return max_sizes, min_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "432.43243243243245"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 200\n",
    "needed_size = 160\n",
    "max_sizes, min_sizes = check_box_sizes('effects/vdb_fire/gasoline_1.webm', size)\n",
    "needed_size * size / max(min_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace0241bc2e54b2487012c7066895071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Processing source_videos/2020-06-23_16-40-40.mp4', max=15…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Closing streams...\n"
     ]
    }
   ],
   "source": [
    "in_video_path = 'source_videos/2020-06-23_16-40-40.mp4'\n",
    "# in_video_path = 'source_videos/stream_OV1_2020-08-01_09_58_11.ts.mp4'\n",
    "# in_video_path = 'source_videos/stream_OV1_2020-08-01_09_58_50.ts.mp4'\n",
    "out_path = 'out/out.mp4'\n",
    "write_debug = False\n",
    "writer = get_coco_writer()\n",
    "\n",
    "cfg = AugmentationConfig()\n",
    "cfg.__dict__.update({\n",
    "    'do_resize': True,\n",
    "    'do_flip': False,\n",
    "    'do_rotate': False,\n",
    "    'do_brightness': True,\n",
    "    'do_gamma': True,\n",
    "    'do_blur': True,\n",
    "    'min_bbox_size': 40,\n",
    "})\n",
    "\n",
    "# e_reader = VideoEffectReader(['effects/vdb_fire/gasoline_3.webm'])\n",
    "# e_reader = VideoEffectReader(['effects/vdb_fire/gasoline_1.webm'], use_alpha=True)\n",
    "e_reader = ImageEffectReader(glob('effects/random_objects/*'), annot_type=None)\n",
    "\n",
    "# Augmentations\n",
    "augment = Augmentations(\n",
    "    [e_reader],\n",
    "    configs=[cfg],\n",
    "    min_n_objects=1,\n",
    "    max_n_objects=1,\n",
    "    debug_level=0,\n",
    "    gen_prob=1,\n",
    "    next_gen_prob=0,\n",
    ")\n",
    "\n",
    "in_stream = cv2.VideoCapture(in_video_path)\n",
    "is_exit = False\n",
    "\n",
    "# Create writer\n",
    "frame_width = int(in_stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(in_stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(in_stream.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(in_stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MPEG')\n",
    "out_stream = cv2.VideoWriter(out_path, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "pbar = tqdm(total=total_frames, desc=f'Processing {in_video_path}')\n",
    "effects_iter = aug_new().get_iter()\n",
    "counter = 0\n",
    "try:\n",
    "    while in_stream.isOpened():\n",
    "        _, image = in_stream.read()\n",
    "        if image is None:\n",
    "            tqdm.write(\"No image in the stream, stopping.\")\n",
    "            break\n",
    "        \n",
    "        if len(augment.objects) == 0:\n",
    "            effects = next(effects_iter)\n",
    "            for effect in effects:\n",
    "                augment.add_effect(effect)\n",
    "#             augment.add_effect(make_effect(0, 0, 0, 0, 1, 0, 1, offset=(1920//2, 1000), size=150))\n",
    "        \n",
    "        frame, debug_frame = augment.augment(image, writer=writer, frame_num=0)\n",
    "        if debug_frame is None:\n",
    "            debug_frame = frame\n",
    "        \n",
    "        out_stream.write(debug_frame if write_debug else frame)\n",
    "        pbar.update(1)\n",
    "        counter += 1\n",
    "        if draw_debug(debug_frame):\n",
    "            break\n",
    "except StopIteration:\n",
    "    tqdm.write('Stop Iteration.')\n",
    "except KeyboardInterrupt:\n",
    "    tqdm.write('Exited.')\n",
    "    is_exit = True\n",
    "finally:\n",
    "    # Close streams.\n",
    "    pbar.close()\n",
    "    tqdm.write('Closing streams...')\n",
    "    in_stream.release()\n",
    "    out_stream.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_stream.release()\n",
    "out_stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import json\n",
    "from itertools import cycle\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ffmpeg_utils\n",
    "from augment_script import process_video, process_images, create_folder, draw_debug, VideoEffectReader, get_coco_writer\n",
    "from augment import Effect, Augmentations, AugmentationConfig\n",
    "from reader import VideoEffectReader, ImageEffectReader\n",
    "from writer import COCO_writer\n",
    "from bbox_utils import (convert_xywh_xyxy, convert_xyxy_xywh,\n",
    "                        blur_contour, resize, rotate, flip,\n",
    "                        get_scale_ratio, resize_by_max_side,\n",
    "                        gamma_correction)\n",
    "\n",
    "\n",
    "def transform_effect(e_image, e_info, segments, cfg):\n",
    "    # Transparency\n",
    "    e_image[:, :, 3:] = e_image[:, :, 3:] * e_info.transparency\n",
    "\n",
    "    # Flip image\n",
    "    if cfg.do_flip and e_info.is_flip:\n",
    "        e_image, _, segments = flip(e_image, segments=segments)\n",
    "\n",
    "    # Contrast & Brightness\n",
    "    if cfg.do_brightness:\n",
    "        e_image[:, :, :3] = cv2.convertScaleAbs(\n",
    "            e_image[:, :, :3], alpha=e_info.gain, beta=e_info.bias)\n",
    "\n",
    "    # Gamma correction\n",
    "    if cfg.do_gamma:\n",
    "        e_image[:, :, :3] = gamma_correction(\n",
    "            e_image[:, :, :3], e_info.gamma)\n",
    "\n",
    "    # Rotate image\n",
    "    if cfg.do_rotate and e_info.angle:\n",
    "        e_image, _, segments = rotate(e_image, e_info.angle, segments=segments)\n",
    "\n",
    "    if cfg.do_blur:\n",
    "        e_image = blur_contour(e_image,\n",
    "            cfg.blur_radius, cfg.contour_radius, blur_image=False)\n",
    "\n",
    "    # Resize image\n",
    "    \n",
    "    print(e_image.shape)\n",
    "    if cfg.do_resize:\n",
    "        e_image, _, segments = resize(e_image, e_info.size, segments=segments)\n",
    "    \n",
    "    offsetx = np.random.uniform(-30, 30)\n",
    "    offsety = np.random.uniform(-200, -120)\n",
    "    offsetx = e_image.shape[1] * (offsetx / 100)\n",
    "    offsety = e_image.shape[0] * (offsety / 100)\n",
    "    \n",
    "    e_image = add_shadow(e_image, (offsetx, offsety))\n",
    "    return e_image, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpImage(img, shadow_off, obj_off, old_shape, start_pos=0):\n",
    "    h, w = old_shape\n",
    "    ow, oh = obj_off\n",
    "    offx, offy = shadow_off\n",
    "    print('start_pos', start_pos)\n",
    "    pts1 = np.float32([[ow, oh],           [ow+w-1, oh],           [ow, oh+h-1-start_pos], [ow+w-1, oh+h-1-start_pos]])\n",
    "    pts2 = np.float32([[ow-offx, oh-offy], [ow+w-1-offx, oh-offy], [ow, oh+h-1-start_pos], [ow+w-1, oh+h-1-start_pos]])\n",
    "    print(pts1)\n",
    "    print(pts2)\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    dst = cv2.warpPerspective(img, M, img.shape[:2][::-1])\n",
    "    return dst\n",
    "\n",
    "\n",
    "def trim_empty(image, segments=None, tolerance=0):\n",
    "    # img is 2D or 3D image data\n",
    "    mask = image > tolerance\n",
    "    if image.ndim == 3:\n",
    "        mask = mask.all(2)\n",
    "    m, n = mask.shape\n",
    "    mask0, mask1 = mask.any(0), mask.any(1)\n",
    "    col_start, col_end = mask0.argmax(), n - mask0[::-1].argmax()\n",
    "    row_start, row_end = mask1.argmax(), m - mask1[::-1].argmax()\n",
    "    return image[row_start:row_end,\n",
    "               col_start:col_end]\n",
    "\n",
    "def add_shadow(e_image, offset, blur_radius=51, max_shadow_opacity=200):\n",
    "    h, w = e_image.shape[:2]\n",
    "    offset = np.array(offset, dtype=np.int32)\n",
    "    print('e_image', e_image.shape)\n",
    "    print('offset', offset)\n",
    "    \n",
    "    if offset[1] < -h:\n",
    "        new_h = -offset[1]\n",
    "        start_pos = int(e_image.shape[0] * 0.05)\n",
    "    else:\n",
    "        new_h = h + (offset[1] if offset[1] > 0 else 0)\n",
    "        start_pos = 0\n",
    "    new_w = w + abs(offset[0])\n",
    "    new_image = np.zeros((new_h, new_w, 4), dtype=np.uint8)\n",
    "    print('new_image', new_image.shape)\n",
    "    \n",
    "    if offset[0] > 0:\n",
    "        if offset[1] < 0:\n",
    "            obj_off = [offset[0], 0]\n",
    "        else:\n",
    "            obj_off = [offset[0], offset[1]]\n",
    "    else:\n",
    "        if offset[1] <= 0:\n",
    "            obj_off = [0, 0]\n",
    "        else:\n",
    "            obj_off = [0, offset[1]]\n",
    "    \n",
    "    new_image[obj_off[1]:h+obj_off[1], obj_off[0]:w+obj_off[0]] = e_image\n",
    "    \n",
    "#     offset[1] *= new_h / h\n",
    "    \n",
    "    blur_padding = blur_radius // 4\n",
    "    shadow = np.zeros((blur_padding * 2 + new_image.shape[0],\n",
    "                       blur_padding * 2 + new_image.shape[1],\n",
    "                       new_image.shape[2] - 3), dtype=np.uint8)\n",
    "    shadow[blur_padding:-blur_padding, blur_padding:-blur_padding] = new_image[:, :, 3:]\n",
    "    shadow = (shadow / 255) * max_shadow_opacity\n",
    "    \n",
    "    shadow = warpImage(shadow, offset, obj_off, (h, w), start_pos)\n",
    "    shadow = cv2.GaussianBlur(shadow, (blur_radius, blur_radius), 0)\n",
    "    if len(shadow.shape) == 2:\n",
    "        shadow = np.expand_dims(shadow, -1)\n",
    "    shadow = shadow[blur_padding:-blur_padding, blur_padding:-blur_padding]\n",
    "    \n",
    "    mask = new_image[..., 3:] / 255\n",
    "    new_image[..., :3] = new_image[..., :3] * mask\n",
    "    new_image[..., 3:] = new_image[..., 3:] + shadow * (1 - mask)\n",
    "    \n",
    "    \n",
    "#     oh, ow = obj_off\n",
    "#     ow = 0\n",
    "#     offx, offy = offset\n",
    "#     pts1 = np.float32([[ow, oh],           [ow+w-1, oh],           [ow, oh+h-1-start_pos], [ow+w-1, oh+h-1-start_pos]])\n",
    "#     for pnt in pts1:\n",
    "#         print(pnt)\n",
    "#         pnt = (int(pnt[0]), int(pnt[1]))\n",
    "#         cv2.circle(new_image, pnt, 10, (0, 255, 0, 255), -1)\n",
    "        \n",
    "#     new_image = trim_empty(new_image)\n",
    "    cv2.imshow('shadow', shadow * (1 - mask))\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, 400, 4)\n",
      "e_image (318, 400, 4)\n",
      "offset [ 400 -318]\n",
      "new_image (318, 800, 4)\n",
      "start_pos 0\n",
      "[[400.   0.]\n",
      " [799.   0.]\n",
      " [400. 317.]\n",
      " [799. 317.]]\n",
      "[[  0. 318.]\n",
      " [399. 318.]\n",
      " [400. 317.]\n",
      " [799. 317.]]\n",
      "obj_off [400, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = e_image.copy()\n",
    "img = resize(img, 400)[0]\n",
    "h, w = img.shape[:2]\n",
    "print(img.shape)\n",
    "offx = int(w * 1)\n",
    "offy = int(h * -1)\n",
    "\n",
    "start_pos = int(img.shape[0] * 0.05)\n",
    "# for pnt in [ [0, h-1-start_pos], [w-1, h-1-start_pos]]:\n",
    "#     print(pnt)\n",
    "#     pnt = (int(pnt[0]), int(pnt[1]))\n",
    "#     cv2.circle(img, pnt, 10, (0, 255, 0, 255), -1)\n",
    "\n",
    "dst = add_shadow(img, (offx, offy))\n",
    "cv2.imshow('test', get_img_with_white_bg(dst))\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 133, 4)\n",
      "e_image (318, 400, 4)\n",
      "offset [  43 -440]\n",
      "new_image (440, 443, 4)\n",
      "start_pos 5\n",
      "[[  0.   0.]\n",
      " [399.   0.]\n",
      " [  0. 312.]\n",
      " [399. 312.]] [[-43. 440.]\n",
      " [356. 440.]\n",
      " [  0. 312.]\n",
      " [399. 312.]]\n"
     ]
    }
   ],
   "source": [
    "e_info = Effect(\n",
    "    reader_id = 0,\n",
    "    idx = 1,\n",
    "    track_id = 1,\n",
    "    size = 400,\n",
    "    offset = (0, 0),\n",
    "    angle = 0,\n",
    "    is_flip = False,\n",
    "    transparency = 100 / 100, \n",
    "    shadow_off = (30, 30),\n",
    "    shadow_trans = 0.8,\n",
    "    gain = 1,\n",
    "    bias = 0,\n",
    "    gamma = 1,\n",
    "    duration = 0,\n",
    "    cur_dur = 0,\n",
    ")\n",
    "cfg = AugmentationConfig()\n",
    "cfg.__dict__.update({\n",
    "    'do_resize': True,\n",
    "    'do_flip': False,\n",
    "    'do_rotate': False,\n",
    "    'do_brightness': True,\n",
    "    'do_gamma': True,\n",
    "    'do_blur': False,\n",
    "    'min_bbox_size': 40,\n",
    "})\n",
    "\n",
    "def get_img_with_white_bg(image):\n",
    "    alpha = image[:, :, 3:].copy()\n",
    "    image = (image[:, :, :3] * (alpha / 255)).astype(np.uint8)\n",
    "    image += (np.ones(image.shape) * (255 - alpha)).astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "it = list(glob('effects/animals/coco_ded_retrieved/*.png'))\n",
    "np.random.shuffle(it)\n",
    "for im_path in it:\n",
    "    e_image = cv2.imread(im_path, -1)\n",
    "    cv2.imshow('image', get_img_with_white_bg(resize(e_image, 400)[0]))\n",
    "    e_image_with_shadow, segments = transform_effect(e_image, e_info, None, cfg)\n",
    "    cv2.imshow('with_shadow', get_img_with_white_bg(e_image_with_shadow))\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "\n",
    "##### General\n",
    "* <s>move everything to config file</s>\n",
    "* написать loop чтобы обработать все видосы\n",
    "\n",
    "##### Preparation\n",
    "* <s>remove clear pixels</s>\n",
    "* remove clear pixels from video\n",
    "\n",
    "##### Augmentation\n",
    "* <s>cover all image</s>\n",
    "* <s>change sizes</s>\n",
    "* <s>flip</s>\n",
    "* <s>add animations</s>\n",
    "* <s>proper resizing</s>\n",
    "* <s>make an offset point a down center point of the effect image.</s>\n",
    "* <s>fix merging with video - fix: Color keying</s>\n",
    "* <s>поиграться с color keying'ом, чтобы более плавные переходы в нём были</s>\n",
    "* <s>change angle</s>\n",
    "* <s>contrast and brightness</s>\n",
    "* <s>gamma correction</s>\n",
    "* <s>find new effects, add smoke</s>\n",
    "* warp perspective\n",
    "\n",
    "##### Annotation\n",
    "* <s>add dynamic bboxes for videos</s>\n",
    "* <s>fix bboxes for some videos</s>\n",
    "* <s>annotate all videos</s>\n",
    "* <s>annotation for images</s>\n",
    "* <s>scaling bboxes</s>\n",
    "* <s>rotating bboxes</s>\n",
    "* <s>Write to COCO</s>\n",
    "* <s>Get class from annotation, not by fixing it for Augmentation object</s>\n",
    "* разметить эффекты не боксом, а полигоном, чтобы можно было нормально поворачивать эффект и при этом иметь нормальный бокс\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with videos\n",
    "\n",
    "#### Scale down with keeping alpha channel\n",
    "```shell\n",
    "ffmpeg -i in.mov -filter:v scale=720:-1 -c:v qtrle out.mov\n",
    "```\n",
    "\n",
    "#### `png` files to `.mov` with alpha\n",
    "```shell\n",
    "ffmpeg -framerate 25 -f image2 -i frames/embergen_gasoline_explosion_a_0.vdb%03d.png -c:v libvpx -pix_fmt yuva420p output.webm\n",
    "```\n",
    "\n",
    "#### `.mov` to `.webm` keeping  alpha channel\n",
    "\n",
    "```shell\n",
    "ffmpeg -i in.mov -c:v libvpx -pix_fmt yuva420p -auto-alt-ref 0 out.webm\n",
    "```\n",
    "\n",
    "#### Extract alpha channel from `.webm`\n",
    "\n",
    "```shell\n",
    "ffmpeg -vcodec libvpx -i in.webm -vf alphaextract -y out.mp4\n",
    "```\n",
    "\n",
    "\n",
    "#### Extract alpha channel from `.mov`\n",
    "\n",
    "```shell\n",
    "ffmpeg -i in.mov -vf alphaextract,format=yuv420p out.mp4\n",
    "```\n",
    "\n",
    "#### Compress resulting video\n",
    "```shell\n",
    "ffmpeg -i out.mp4 -vcodec h264 -b:v 1000k -acodec mp2 compressed_out.mp4 -y\n",
    "```\n",
    "\n",
    "#### Get first `n` frames\n",
    "```shell\n",
    "ffmpeg -i in.mp4 -frames:v 249 -c copy out.mp4\n",
    "```\n",
    "\n",
    "#### Cut video from `ss` till `t`\n",
    "```shell\n",
    "ffmpeg -ss 00:00:8.25 -i in.mp4 -t 00:00:8.25 out.mp4                                                               \n",
    "```\n",
    "\n",
    "#### Merge video with alpha channel in `.mov` file\n",
    "```shell\n",
    "ffmpeg -i in.mp4 -i alpha_in.mp4 -filter_complex [0][1]alphamerge -c:v qtrle out.mov\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
