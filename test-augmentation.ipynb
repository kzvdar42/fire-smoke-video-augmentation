{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ffmpeg_utils\n",
    "from augment_script import process_video, process_images\n",
    "from augment import Augmentations\n",
    "from reader import VideoEffectReader, ImageEffectReader\n",
    "from writer import COCO_writer\n",
    "from bbox_utils import get_scale_ratio, resize_by_max_side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_type = 'fire'\n",
    "e_type = 'smoke'\n",
    "e_type = 'real_fire_smoke'\n",
    "\n",
    "def get_effect_paths(e_type):\n",
    "    assert e_type in ['fire', 'smoke', 'real_fire_smoke'], 'Unsupported'\n",
    "    raw_png_effects_path  = f'effects/raw_{e_type}_images'\n",
    "    prep_png_effects_path = f'effects/prep_{e_type}_images'\n",
    "    raw_mov_effects_path  = f'effects/raw_{e_type}_vid'\n",
    "    prep_mov_effects_path = f'effects/prep_{e_type}_vid'\n",
    "    return (raw_png_effects_path, prep_png_effects_path,\n",
    "            raw_mov_effects_path, prep_mov_effects_path)\n",
    "\n",
    "(raw_png_effects_path, prep_png_effects_path,\n",
    " raw_mov_effects_path, prep_mov_effects_path) = get_effect_paths(e_type)\n",
    "\n",
    "\n",
    "vid_out_path = 'output/out.mp4'\n",
    "annot_out_path = 'output/annotations/instances_default.json'\n",
    "\n",
    "# Create folders\n",
    "for path in [raw_png_effects_path, prep_png_effects_path,\n",
    "             raw_mov_effects_path, prep_mov_effects_path,\n",
    "             os.path.split(vid_out_path)[0],\n",
    "             os.path.split(annot_out_path)[0]]:\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and trim empty pixels\n",
    "raw_png_effects_path = 'effects/non_funny'\n",
    "prep_png_effects_path = 'effects/prep_non_funny'\n",
    "e_type = 'non-funny'\n",
    "# for i, effect_path in enumerate(glob(os.path.join(raw_png_effects_path, '*.png'))):\n",
    "#     e_img = cv2.imread(effect_path, cv2.IMREAD_UNCHANGED)\n",
    "#     # Trim empty pixels\n",
    "#     y, x = e_img[:, :, 3].nonzero()\n",
    "#     minx, miny = np.min(x), np.min(y)\n",
    "#     maxx, maxy = np.max(x), np.max(y)\n",
    "#     e_img = e_img[miny:maxy, minx:maxx]\n",
    "#     # Resize to 512px\n",
    "#     scale_ratio = get_scale_ratio(e_img, 512)\n",
    "#     e_img = resize_by_max_side(e_img, scale_ratio)\n",
    "#     os.makedirs(prep_png_effects_path, exist_ok=True)\n",
    "#     cv2.imwrite(os.path.join(prep_png_effects_path, f'{e_type}-{i}.png'), e_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename videos\n",
    "# for i, mov_path in enumerate(glob(os.path.join(raw_mov_effects_path, '*.mov'))):\n",
    "#     print(mov_path)\n",
    "#     path = os.path.split(mov_path)[0]\n",
    "#     os.rename(mov_path, os.path.join(path, f'{e_type}-{i}.mov'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and extract alpha videos\n",
    "rewrite = False\n",
    "# for input_path in glob(os.path.join(raw_mov_effects_path, '*.mov')):\n",
    "#     input_path = os.path.abspath(input_path)\n",
    "#     filename = os.path.splitext(os.path.split(input_path)[1])[0]\n",
    "#     out_path = os.path.join(prep_mov_effects_path, filename + '.webm')\n",
    "#     out_path = os.path.abspath(out_path)\n",
    "#     ffmpeg_utils.convert_mov2webm(input_path, out_path, y=rewrite)\n",
    "#     ffmpeg_utils.extract_alpha(out_path, y=rewrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e_paths = get_effect_paths('fire')\n",
    "e_paths = get_effect_paths('real_fire_smoke')\n",
    "prep_e_png_fire_path, prep_e_mov_fire_path = e_paths[1], e_paths[3]\n",
    "e_paths = get_effect_paths('smoke')\n",
    "prep_e_png_smoke_path, prep_e_mov_smoke_path = e_paths[1], e_paths[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['effects/animals/retrieved\\\\0000001.png',\n",
       "  'effects/animals/retrieved\\\\0000002.png',\n",
       "  'effects/animals/retrieved\\\\0000003.png',\n",
       "  'effects/animals/retrieved\\\\0000004.png',\n",
       "  'effects/animals/retrieved\\\\0000005.png',\n",
       "  'effects/animals/retrieved\\\\0000006.png',\n",
       "  'effects/animals/retrieved\\\\0000007.png',\n",
       "  'effects/animals/retrieved\\\\0000008.png',\n",
       "  'effects/animals/retrieved\\\\0000009.png',\n",
       "  'effects/animals/retrieved\\\\0000010.png',\n",
       "  'effects/animals/retrieved\\\\0000011.png',\n",
       "  'effects/animals/retrieved\\\\0000012.png',\n",
       "  'effects/animals/retrieved\\\\0000013.png',\n",
       "  'effects/animals/retrieved\\\\0000014.png',\n",
       "  'effects/animals/retrieved\\\\0000015.png'],\n",
       " ['effects/prep_real_fire_smoke_vid\\\\fire-1.webm',\n",
       "  'effects/prep_real_fire_smoke_vid\\\\fire-2.webm',\n",
       "  'effects/prep_real_fire_smoke_vid\\\\fire-3.webm',\n",
       "  'effects/prep_real_fire_smoke_vid\\\\smoke-1.webm',\n",
       "  'effects/prep_real_fire_smoke_vid\\\\smoke-2.webm'],\n",
       " ['effects/prep_smoke_images\\\\smoke-0.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-1.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-2.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-3.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-4.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-5.png'],\n",
       " ['effects/prep_smoke_vid\\\\smoke-0.webm',\n",
       "  'effects/prep_smoke_vid\\\\smoke-1.webm'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_png_fire = glob(os.path.join(prep_e_png_fire_path, '*.png'))\n",
    "e_png_fire = glob(os.path.join('effects/animals/retrieved', '*.png'))\n",
    "e_mov_fire = glob(os.path.join(prep_e_mov_fire_path, '*.webm'))\n",
    "e_png_smoke = glob(os.path.join(prep_e_png_smoke_path, '*.png'))\n",
    "e_mov_smoke = glob(os.path.join(prep_e_mov_smoke_path, '*.webm'))\n",
    "e_png_fire[:15], e_mov_fire[:15], e_png_smoke[:15], e_mov_smoke[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['source_videos\\\\2020-06-23_16-40-40.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_09_58_11.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_09_58_50.ts.mp4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_videos = glob('source_videos/*')\n",
    "source_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.64s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# COCO_writer\n",
    "coco_writer = COCO_writer([\n",
    "    {\n",
    "        'name': 'Fire',\n",
    "        'supercategory': '',\n",
    "        'id': 2,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Smoke',\n",
    "        'supercategory': '',\n",
    "        'id': 4,\n",
    "    },\n",
    "])\n",
    "\n",
    "e_readers = [\n",
    "#     VideoEffectReader(e_mov_fire[1:2]),\n",
    "    ImageEffectReader(e_png_fire, annot_type='coco', preload=False),\n",
    "]\n",
    "\n",
    "\n",
    "# Augmentations\n",
    "fire_augment = Augmentations(\n",
    "    e_readers,\n",
    "    config_path='augment_config.yaml',\n",
    "    mov_min_size= 300,\n",
    "    mov_max_size= 900,\n",
    "    do_resize=True,\n",
    "    do_flip=True,\n",
    "    do_rotate=True,\n",
    "    do_brightness=True,\n",
    "    do_gamma=True,\n",
    "    do_blur=True,\n",
    "    blur_radius=11,\n",
    "    contour_radius=10,\n",
    "    debug_level=2,\n",
    "    min_n_objects=10,\n",
    "    max_n_objects=10,\n",
    "    use_alpha=True,\n",
    "    min_transparency=100,\n",
    "    max_transparency=100,\n",
    "    ck_start=1,\n",
    "    ck_range=10,\n",
    "    min_duration=1,\n",
    "    max_duration=2,\n",
    ")\n",
    "\n",
    "# smoke_augment = Augmentations(\n",
    "#     e_png_smoke,\n",
    "#     e_mov_smoke,\n",
    "#     config_path='augment_config.yaml',\n",
    "#     do_resize=True,\n",
    "#     do_flip=True,\n",
    "#     do_rotate=False,\n",
    "#     do_contrast=False,\n",
    "#     debug_level=2,\n",
    "#     ck_start=2,\n",
    "#     ck_range=15,\n",
    "#     max_n_objects=3,\n",
    "#     use_alpha=True\n",
    "# )\n",
    "\n",
    "augmentations = [\n",
    "    fire_augment,\n",
    "#     smoke_augment\n",
    "]\n",
    "\n",
    "# process_video(source_videos[0], augmentations, vid_out_path, coco_writer, show_debug=True)\n",
    "\n",
    "# # Write annotations.\n",
    "# os.makedirs(os.path.split(annot_out_path)[0], exist_ok=True)\n",
    "# coco_writer.write_result(annot_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['effects/animals/retrieved\\\\0000001.png',\n",
       " 'effects/animals/retrieved\\\\0000002.png',\n",
       " 'effects/animals/retrieved\\\\0000003.png',\n",
       " 'effects/animals/retrieved\\\\0000004.png',\n",
       " 'effects/animals/retrieved\\\\0000005.png',\n",
       " 'effects/animals/retrieved\\\\0000006.png',\n",
       " 'effects/animals/retrieved\\\\0000007.png',\n",
       " 'effects/animals/retrieved\\\\0000008.png',\n",
       " 'effects/animals/retrieved\\\\0000009.png',\n",
       " 'effects/animals/retrieved\\\\0000010.png',\n",
       " 'effects/animals/retrieved\\\\0000011.png',\n",
       " 'effects/animals/retrieved\\\\0000012.png',\n",
       " 'effects/animals/retrieved\\\\0000013.png',\n",
       " 'effects/animals/retrieved\\\\0000014.png',\n",
       " 'effects/animals/retrieved\\\\0000015.png']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_readers[0].loaded[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                           | 184/15004 [01:36<2:09:26,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "process_video(source_videos[0], augmentations, vid_out_path, coco_writer, show_debug=True, write_debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for `id=0` for all annotations\n",
    "# for path in glob('effects/prep_real_fire_smoke_vid/annotations/fire-3.json'):\n",
    "#     with open(path) as in_file:\n",
    "#         j = json.load(in_file)\n",
    "#     for i, annot in enumerate(j['annotations']):\n",
    "#         annot['id'] = i\n",
    "#         j['annotations'][i] = annot\n",
    "    \n",
    "#     with open(path, 'w') as out_file:\n",
    "#         out_file.write(json.dumps(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_poly(poly, angle, cx, cy, h, w):\n",
    "    \"\"\"Rotate the polygon.\"\"\"\n",
    "    poly = poly.reshape(-1, 2)\n",
    "    poly = np.hstack(\n",
    "        (poly, np.ones((poly.shape[0], 1), dtype=poly[0][0].dtype)))\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((cx, cy), angle, 1.0)\n",
    "\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cx\n",
    "    M[1, 2] += (nH / 2) - cy\n",
    "    # Prepare the vector to be transformed\n",
    "    calculated = np.dot(M, poly.T).T\n",
    "    return calculated#.reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners = np.zeros((8))\n",
    "corners = corners.reshape(-1, 2)\n",
    "corners = np.hstack(\n",
    "    (corners, np.ones((corners.shape[0], 1), dtype=type(corners[0][0]))))\n",
    "corners.shape\n",
    "corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbox_utils import convert_xywh_xyxy, convert_xyxy_xywh, blur_contour, rotate_im\n",
    "\n",
    "def rotate(image, angle, bboxes=None, segments=None):\n",
    "    h, w = image.shape[:2]\n",
    "    cx, cy = w // 2, h // 2\n",
    "\n",
    "    # Rotate image.\n",
    "    image = rotate_im(image, angle)\n",
    "\n",
    "    # Scale back\n",
    "    scale_factor_x = image.shape[1] / w\n",
    "    scale_factor_y = image.shape[0] / h\n",
    "\n",
    "    image = cv2.resize(image, (w, h))\n",
    "    \n",
    "    enclosing_polygons = None\n",
    "    if segments is not None:\n",
    "        M = cv2.getRotationMatrix2D((cx, cy), angle, 1.0)\n",
    "        enclosing_polygons = []\n",
    "        for segment in segments:\n",
    "            seg = rotate_poly(segment, angle, cx, cy, h, w)\n",
    "            seg = seg / [scale_factor_x, scale_factor_y]\n",
    "            enclosing_polygons.append(seg)\n",
    "        enclosing_polygons = np.array(enclosing_polygons).astype(np.int32)\n",
    "        segments = enclosing_polygons\n",
    "    elif bboxes is not None:\n",
    "        corners = get_corners(bboxes)\n",
    "        # Rotate corners.\n",
    "        enclosing_polygons = rotate_box(corners, angle, cx, cy, h, w)\n",
    "    if enclosing_polygons is not None:\n",
    "        # Calculate enclosing bbox.\n",
    "        bboxes = []\n",
    "        for poly in enclosing_polygons:\n",
    "            bbox = cv2.boundingRect(poly)\n",
    "            bbox = convert_xywh_xyxy(bbox, w, h)\n",
    "            bboxes.append(bbox)\n",
    "        bboxes = np.array(bboxes, dtype=np.float32)\n",
    "#         Scale back.\n",
    "        bboxes[:, :4] /= [scale_factor_x, scale_factor_y] * 2\n",
    "\n",
    "    return image, bboxes, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pycocotools.coco import COCO\n",
    "# animals_coco = COCO('effects/animals/animals.json')\n",
    "# writer = COCO_writer(animals_coco.dataset['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ce7b763da841fcb0519e9d27186577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19267.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 41  20 184 169]\n",
      "[  2  12 543 279]\n",
      "[ 49  21 198 315]\n",
      "[ 32  36 576 229]\n",
      "[ 60  28 346 390]\n",
      "[ 49  33 306 269]\n",
      "[ 19  37 211 252]\n",
      "[ 57  48 410 404]\n",
      "[ 22  55 492 180]\n"
     ]
    }
   ],
   "source": [
    "from bbox_utils import convert_xywh_xyxy, convert_xyxy_xywh, blur_contour, rotate_im\n",
    "\n",
    "\n",
    "pbar = tqdm(total=len(animals_coco.imgs))\n",
    "for img_id, img_info in animals_coco.imgs.items():\n",
    "    read_img_name = os.path.split(img_info['image'])[1]\n",
    "    path = 'effects/animals/animals/' + read_img_name\n",
    "    image = cv2.imread(path)\n",
    "    ann_ids = animals_coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "    for obj in animals_coco.loadAnns(ann_ids):\n",
    "        if obj['area'] < 3000:\n",
    "            continue\n",
    "        mask = np.zeros((*image.shape[:2], 1), dtype=np.uint8)\n",
    "        segments = []\n",
    "        for segment in obj['segmentation'][:1]:\n",
    "            segment = np.array(segment).reshape(-1, 1, 2).astype(np.int32)\n",
    "            segments.append(segment)\n",
    "        segments = np.array(segments).reshape(-1, 1, 2)\n",
    "        cv2.fillPoly(mask, [segments], (255))\n",
    "        img = image.copy()\n",
    "        img = np.concatenate((img, mask), -1)\n",
    "        img = blur_contour(img, blur_radius=21, contour_radius=15, blur_image=False)\n",
    "        \n",
    "        y, x = img[:, :, 3].nonzero()\n",
    "        minx, miny = np.min(x), np.min(y)\n",
    "        maxx, maxy = np.max(x), np.max(y)\n",
    "        img = img[miny:maxy, minx:maxx]\n",
    "        \n",
    "        \n",
    "        segmentations = []\n",
    "        for segment in segments:\n",
    "            seg = np.array(segment).reshape(-1, 1, 2) - (minx, miny)\n",
    "            h, w = img.shape[:2]\n",
    "            seg[:, :, 0] = np.clip(seg[:, :, 0], 0, w - 1)\n",
    "            seg[:, :, 1] = np.clip(seg[:, :, 1], 0, h - 1)\n",
    "            segmentations.append(seg)\n",
    "        segments = segmentations\n",
    "        \n",
    "        img, _, segments = rotate(img, angle=15, segments=segments)\n",
    "        img, mask = img[:, :, :3].copy(), img[:, :, 3:].copy()\n",
    "        \n",
    "        bbox = cv2.boundingRect(segments)\n",
    "        bbox = convert_xywh_xyxy(bbox, *img.shape[:2][::-1])\n",
    "        print(bbox)\n",
    "        cv2.rectangle(img, tuple(bbox[:2]), tuple(bbox[2:4]), (22, 48, 163), 2)\n",
    "        for segment in segments:\n",
    "            cv2.drawContours(img, segments, -1, (0, 0, 255), 4)\n",
    "        cv2.imshow('orig_image', image)\n",
    "        cv2.imshow('img_orig', img)\n",
    "        cv2.imshow('img', (img * (mask / 255)).astype(np.uint8))\n",
    "        cv2.imshow('mask', mask)\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    if key == ord('q'):\n",
    "            break\n",
    "    pbar.update(1)\n",
    "cv2.destroyAllWindows()\n",
    "# writer.write_result('effects/animals/retrieved.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 720, 1)\n",
      "(6, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(10, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n",
      "(500, 720, 1)\n",
      "(10, 1, 2) int32\n",
      "0.9921568627450981 0.0\n",
      "255\n",
      "253\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-8a00ba1db17b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'e_frame'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "effect_path = 'effects/prep_real_fire_smoke_vid/fire-3'\n",
    "cap = cv2.VideoCapture(f'{effect_path}.webm')\n",
    "alpha_cap = cv2.VideoCapture(f'{effect_path}_alpha.mp4')\n",
    "while True:\n",
    "    ret, e_frame = cap.read()\n",
    "    a_ret, e_alpha = alpha_cap.read()\n",
    "    init_e_alpha = e_alpha.copy()\n",
    "    if not ret or not a_ret:\n",
    "        print(ret, a_ret)\n",
    "        break\n",
    "#     rgb_sum = np.expand_dims(np.sum(e_alpha, axis=2), -1)\n",
    "#     e_alpha = np.clip(rgb_sum, 0, 255, dtype=np.uint8)\n",
    "    e_alpha = e_alpha[:, :, :1]\n",
    "    print(e_alpha.shape)\n",
    "    e_mask = np.ones(e_alpha.shape, dtype=np.uint8) * 255\n",
    "    e_frame = np.concatenate((e_frame, e_alpha), axis=2)\n",
    "    # Blur\n",
    "    blur_radius = 21\n",
    "    contour_radius = 5\n",
    "    \n",
    "    \n",
    "    image, alpha = e_frame[:, :, :3], e_frame[:, :, 3:].copy()\n",
    "\n",
    "    contours, _ = cv2.findContours(alpha.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(contours[0].shape, contours[0].dtype)\n",
    "    cv2.boundingRect(contours[0])\n",
    "    \n",
    "    b_rad = (blur_radius, blur_radius)\n",
    "    blurred_img = image#cv2.GaussianBlur(image, b_rad, 0)\n",
    "    alpha[:, :, 0] = cv2.GaussianBlur(alpha, b_rad, 0)\n",
    "\n",
    "    mask = np.zeros((*image.shape[:2], 1), np.ubyte)\n",
    "    cv2.drawContours(mask, contours, -1, (1), contour_radius)\n",
    "    output = np.where(mask, blurred_img, image)\n",
    "    print((alpha / 255).max(), np.median(alpha / 255))\n",
    "    print(output.max())\n",
    "    output[...] = output * (alpha / 255)\n",
    "    print(output.max())\n",
    "    cv2.imshow('alpha', init_e_alpha)\n",
    "    cv2.imshow('mask', mask * 255)\n",
    "    cv2.imshow('output', output)\n",
    "    cv2.imshow('e_frame', e_frame)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augment import Augmentations\n",
    "from augment_script import _process_image\n",
    "from bbox_utils import (convert_xywh_xyxy, convert_xyxy_xywh,\n",
    "                        resize, rotate, flip, gamma_correction,\n",
    "                        blur_contour)\n",
    "\n",
    "augment = Augmentations.augment\n",
    "merge_images = Augmentations.merge_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f blur_contour process_video(source_videos[0], augmentations, vid_out_path, coco_writer, show_debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob(os.path.join('ufa/images', f'*.jpg'))\n",
    "out_path = 'output/test'\n",
    "show_debug, write_debug = False, False\n",
    "%lprun -f process_images process_images(images, augmentations, out_path, coco_writer, show_debug, write_debug, n_workers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5922650026558175 0.9899783176964153 0.8003302973044949\n",
      "-9.670270866233837 8.323729912185293 -0.022608726770813894\n"
     ]
    }
   ],
   "source": [
    "a = np.random.normal(loc=0.8, scale=0.05, size=10000)\n",
    "b = np.random.normal(loc=0, scale=2.5, size=10000)\n",
    "print(a.min(), a.max(), a.mean())\n",
    "print(b.min(), b.max(), b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob('effects/prep_non_funny/*.png')\n",
    "images = glob(os.path.join('ufa/images', f'*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip([0, 2, 3], 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('effects/prep_real_fire_smoke_vid/smoke-2.webm')\n",
    "cur_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "print(cur_pos)\n",
    "cap.read()\n",
    "print(cap.get(cv2.CAP_PROP_POS_FRAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "\n",
    "##### General\n",
    "* <s>move everything to config file</s>\n",
    "* написать loop чтобы обработать все видосы\n",
    "\n",
    "##### Preparation\n",
    "* <s>remove clear pixels</s>\n",
    "* remove clear pixels from video\n",
    "\n",
    "##### Augmentation\n",
    "* <s>cover all image</s>\n",
    "* <s>change sizes</s>\n",
    "* <s>flip</s>\n",
    "* <s>add animations</s>\n",
    "* <s>proper resizing</s>\n",
    "* <s>make an offset point a down center point of the effect image.</s>\n",
    "* <s>fix merging with video - fix: Color keying</s>\n",
    "* <s>поиграться с color keying'ом, чтобы более плавные переходы в нём были</s>\n",
    "* <s>change angle</s>\n",
    "* <s>contrast and brightness</s>\n",
    "* <s>gamma correction</s>\n",
    "* <s>find new effects, add smoke</s>\n",
    "* warp perspective\n",
    "\n",
    "##### Annotation\n",
    "* <s>add dynamic bboxes for videos</s>\n",
    "* <s>fix bboxes for some videos</s>\n",
    "* <s>annotate all videos</s>\n",
    "* <s>annotation for images</s>\n",
    "* <s>scaling bboxes</s>\n",
    "* <s>rotating bboxes</s>\n",
    "* <s>Write to COCO</s>\n",
    "* <s>Get class from annotation, not by fixing it for Augmentation object</s>\n",
    "* разметить эффекты не боксом, а полигоном, чтобы можно было нормально поворачивать эффект и при этом иметь нормальный бокс\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with videos\n",
    "\n",
    "#### Scale down with keeping alpha channel\n",
    "```shell\n",
    "ffmpeg -i in.mov -filter:v scale=720:-1 -c:v qtrle out.mov\n",
    "```\n",
    "\n",
    "#### `.mov` to `.webm` keeping  alpha channel\n",
    "\n",
    "```shell\n",
    "ffmpeg -i in.mov -c:v libvpx -pix_fmt yuva420p -auto-alt-ref 0 out.webm\n",
    "```\n",
    "\n",
    "#### Extract alpha channel from `.webm`\n",
    "\n",
    "```shell\n",
    "ffmpeg -vcodec libvpx -i in.webm -vf alphaextract -y out.mp4\n",
    "```\n",
    "\n",
    "\n",
    "#### Extract alpha channel from `.mov`\n",
    "\n",
    "```shell\n",
    "ffmpeg -i in.mov -vf alphaextract,format=yuv420p out.mp4\n",
    "```\n",
    "\n",
    "#### Compress resulting video\n",
    "```shell\n",
    "ffmpeg -i out.mp4 -vcodec h264 -b:v 1000k -acodec mp2 compressed_out.mp4 -y\n",
    "```\n",
    "\n",
    "#### Get first `n` frames\n",
    "```shell\n",
    "ffmpeg -i in.mp4 -frames:v 249 -c copy out.mp4\n",
    "```\n",
    "\n",
    "#### Cut video from `ss` till `t`\n",
    "```shell\n",
    "ffmpeg -ss 00:00:8.25 -i in.mp4 -t 00:00:8.25 out.mp4                                                               \n",
    "```\n",
    "\n",
    "#### Merge video with alpha channel in `.mov` file\n",
    "```shell\n",
    "ffmpeg -i in.mp4 -i alpha_in.mp4 -filter_complex [0][1]alphamerge -c:v qtrle out.mov\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
