{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ffmpeg_utils\n",
    "from augment import Augmentations\n",
    "from writer import COCO_writer\n",
    "from bbox_utils import get_scale_ratio, resize_by_max_side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_type = 'fire'\n",
    "e_type = 'smoke'\n",
    "\n",
    "def get_effect_paths(e_type):\n",
    "    assert e_type in ['fire', 'smoke'], \"Unsupported\"\n",
    "    raw_png_effects_path  = f'effects/raw_{e_type}_images'\n",
    "    prep_png_effects_path = f'effects/prep_{e_type}_images'\n",
    "    raw_mov_effects_path  = f'effects/raw_{e_type}_vid'\n",
    "    prep_mov_effects_path = f'effects/prep_{e_type}_vid'\n",
    "    return (raw_png_effects_path, prep_png_effects_path,\n",
    "            raw_mov_effects_path, prep_mov_effects_path)\n",
    "\n",
    "(raw_png_effects_path, prep_png_effects_path,\n",
    " raw_mov_effects_path, prep_mov_effects_path) = get_effect_paths(e_type)\n",
    "\n",
    "\n",
    "vid_out_path = 'output/out.mp4'\n",
    "annot_out_path = 'output/annotations/instances_default.json'\n",
    "\n",
    "# Create folders\n",
    "for path in [raw_png_effects_path, prep_png_effects_path,\n",
    "             raw_mov_effects_path, prep_mov_effects_path,\n",
    "             os.path.split(vid_out_path)[0],\n",
    "             os.path.split(annot_out_path)[0]]:\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and trim empty pixels\n",
    "# for i, effect_path in enumerate(glob(os.path.join(raw_png_effects_path, '*.png'))):\n",
    "#     e_img = cv2.imread(effect_path, cv2.IMREAD_UNCHANGED)\n",
    "#     # Trim empty pixels\n",
    "#     y, x = e_img[:, :, 3].nonzero()\n",
    "#     minx, miny = np.min(x), np.min(y)\n",
    "#     maxx, maxy = np.max(x), np.max(y)\n",
    "#     e_img = e_img[miny:maxy, minx:maxx]\n",
    "#     # Resize to 512px\n",
    "#     scale_ratio = get_scale_ratio(e_img, 512)\n",
    "#     e_img = resize_by_max_side(e_img, scale_ratio)\n",
    "#     cv2.imwrite(os.path.join(prep_png_effects_path, f'{e_type}-{i}.png'), e_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename videos\n",
    "# for i, mov_path in enumerate(glob(os.path.join(raw_mov_effects_path, '*.mov'))):\n",
    "#     print(mov_path)\n",
    "#     path = os.path.split(mov_path)[0]\n",
    "#     os.rename(mov_path, os.path.join(path, f'{e_type}-{i}.mov'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and extract alpha videos\n",
    "\n",
    "# for input_path in glob(os.path.join(raw_mov_effects_path, '*.mov')):\n",
    "#     input_path = os.path.abspath(input_path)\n",
    "#     filename = os.path.splitext(os.path.split(input_path)[1])[0]\n",
    "#     out_path = os.path.join(prep_mov_effects_path, filename + '.webm')\n",
    "#     out_path = os.path.abspath(out_path)\n",
    "#     ffmpeg_utils.convert_mov2webm(input_path, out_path, y=True)\n",
    "#     ffmpeg_utils.extract_alpha(out_path, y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_paths = get_effect_paths('fire')\n",
    "prep_e_png_fire_path, prep_e_mov_fire_path = e_paths[1], e_paths[3]\n",
    "e_paths = get_effect_paths('smoke')\n",
    "prep_e_png_smoke_path, prep_e_mov_smoke_path = e_paths[1], e_paths[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['effects/prep_fire_images\\\\fire-0.png',\n",
       "  'effects/prep_fire_images\\\\fire-1.png',\n",
       "  'effects/prep_fire_images\\\\fire-2.png'],\n",
       " ['effects/prep_fire_vid\\\\fire-0.webm',\n",
       "  'effects/prep_fire_vid\\\\fire-1.webm',\n",
       "  'effects/prep_fire_vid\\\\fire-2.webm',\n",
       "  'effects/prep_fire_vid\\\\fire-3.webm',\n",
       "  'effects/prep_fire_vid\\\\fire-4.webm',\n",
       "  'effects/prep_fire_vid\\\\fire-5.webm',\n",
       "  'effects/prep_fire_vid\\\\fire-6.webm',\n",
       "  'effects/prep_fire_vid\\\\fire-7.webm'],\n",
       " ['effects/prep_smoke_images\\\\smoke-0.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-1.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-2.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-3.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-4.png',\n",
       "  'effects/prep_smoke_images\\\\smoke-5.png'],\n",
       " ['effects/prep_smoke_vid\\\\smoke-0.webm',\n",
       "  'effects/prep_smoke_vid\\\\smoke-1.webm'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_png_fire = glob(os.path.join(prep_e_png_fire_path, '*.png'))\n",
    "e_mov_fire = glob(os.path.join(prep_e_mov_fire_path, '*.webm'))\n",
    "e_png_smoke = glob(os.path.join(prep_e_png_smoke_path, '*.png'))\n",
    "e_mov_smoke = glob(os.path.join(prep_e_mov_smoke_path, '*.webm'))\n",
    "e_png_fire, e_mov_fire, e_png_smoke, e_mov_smoke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['source_videos\\\\2020-06-23_16-40-40.mp4',\n",
       " 'source_videos\\\\2020-06-23_17-40-41.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_09_58_11.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_09_58_50.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_10_00_12.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_10_00_39.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_10_01_29.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_10_01_56.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_10_02_31.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_10_03_28.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_10_04_06.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_10_04_34.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_10_05_28.ts.mp4',\n",
       " 'source_videos\\\\stream_OV1_2020-08-01_11_59_21.ts.mp4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_videos = glob('source_videos/*')\n",
    "source_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(in_video_path, augmentations, writer, out_path):\n",
    "    in_stream = cv2.VideoCapture(in_video_path)\n",
    "    \n",
    "    # Create writer\n",
    "    frame_width  = int(in_stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(in_stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_rate   = int(in_stream.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(in_stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    out_stream = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'MPEG'), frame_rate, (frame_width, frame_height))\n",
    "    \n",
    "    \n",
    "    pbar = tqdm(total=total_frames)\n",
    "    frame_num = 0\n",
    "    try:\n",
    "        while in_stream.isOpened():\n",
    "            _, frame = in_stream.read()\n",
    "            if frame is None:\n",
    "                print(\"No image in the stream, stopping.\")\n",
    "                break\n",
    "\n",
    "            image_name = f'image_{10:06d}.jpg'\n",
    "            writer.add_frame(*frame.shape[:2], image_name)\n",
    "            for augment in augmentations:\n",
    "                frame = augment.augment(frame, frame_num, coco_writer)\n",
    "            out_stream.write(frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "            cv2.imshow('annotated', frame)\n",
    "            # Exit on key `q`.\n",
    "            frame_num += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('Exited.')\n",
    "    finally:\n",
    "        # Close streams.\n",
    "        in_stream.release()\n",
    "        out_stream.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4d0d80f6bd4687bb85544f2a49dbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15004.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# COCO_writer\n",
    "coco_writer = COCO_writer([\n",
    "    {\n",
    "        'name': 'Fire',\n",
    "        'supercategory': '',\n",
    "        'id': 2,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Smoke',\n",
    "        'supercategory': '',\n",
    "        'id': 4,\n",
    "    },\n",
    "])\n",
    "\n",
    "\n",
    "# Augmentations\n",
    "fire_augment = Augmentations(\n",
    "    e_png_fire,\n",
    "    e_mov_fire,\n",
    "    config_path='augment_config.yaml',\n",
    "    do_resize=True,\n",
    "    do_flip=True,\n",
    "    do_rotate=False,\n",
    "    debug_level=2,\n",
    "    max_n_objects=3,\n",
    ")\n",
    "\n",
    "smoke_augment = Augmentations(\n",
    "    e_png_smoke,\n",
    "    e_mov_smoke,\n",
    "    config_path='augment_config.yaml',\n",
    "    do_resize=True,\n",
    "    do_flip=True,\n",
    "    do_rotate=False,\n",
    "    do_contrast=False,\n",
    "    debug_level=2,\n",
    "    ck_start=2,\n",
    "    ck_range=15,\n",
    "    max_n_objects=3,\n",
    "#     use_alpha=True\n",
    ")\n",
    "\n",
    "augmentations = [\n",
    "#     fire_augment,\n",
    "    smoke_augment\n",
    "]\n",
    "\n",
    "process_video(source_videos[0], augmentations, coco_writer, vid_out_path)\n",
    "\n",
    "# Write annotations.\n",
    "os.makedirs(os.path.split(annot_out_path)[0], exist_ok=True)\n",
    "coco_writer.write_result(annot_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7270618133635374 1.3331710971204895 0.9996325724772649\n",
      "-17.374571375683512 19.272189663101283 0.005024089740818967\n"
     ]
    }
   ],
   "source": [
    "a = np.random.normal(loc=1, scale=0.075, size=10000)\n",
    "b = np.random.normal(loc=0, scale=5, size=10000)\n",
    "print(a.min(), a.max(), a.mean())\n",
    "print(b.min(), b.max(), b.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "\n",
    "##### General\n",
    "* <s>move everything to config file</s>\n",
    "* написать loop чтобы обработать все видосы\n",
    "\n",
    "##### Preparation\n",
    "* <s>remove clear pixels</s>\n",
    "* remove clear pixels from video\n",
    "\n",
    "##### Augmentation\n",
    "* <s>cover all image</s>\n",
    "* <s>change sizes</s>\n",
    "* <s>flip</s>\n",
    "* <s>add animations</s>\n",
    "* <s>proper resizing</s>\n",
    "* <s>make an offset point a down center point of the effect image.</s>\n",
    "* <s>fix merging with video - fix: Color keying</s>\n",
    "* <s>поиграться с color keying'ом, чтобы более плавные переходы в нём были</s>\n",
    "* <s>change angle</s>\n",
    "* <s>contrast and brightness</s>\n",
    "* <s>gamma correction</s>\n",
    "* <s>find new effects, add smoke</s>\n",
    "* warp perspective\n",
    "\n",
    "##### Annotation\n",
    "* <s>add dynamic bboxes for videos</s>\n",
    "* <s>fix bboxes for some videos</s>\n",
    "* <s>annotate all videos</s>\n",
    "* <s>annotation for images</s>\n",
    "* <s>scaling bboxes</s>\n",
    "* <s>rotating bboxes</s>\n",
    "* <s>Write to COCO</s>\n",
    "* <s>Get class from annotation, not by fixing it for Augmentation object</s>\n",
    "* разметить эффекты не боксом, а полигоном, чтобы можно было нормально поворачивать эффект и при этом иметь нормальный бокс\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with videos\n",
    "\n",
    "#### Scale down with keeping alpha channel\n",
    "```shell\n",
    "ffmpeg -i in.mov -filter:v scale=720:-1 -c:v qtrle out.mov\n",
    "```\n",
    "\n",
    "#### `.mov` to `.webm` keeping  alpha channel\n",
    "\n",
    "```shell\n",
    "ffmpeg -i in.mov -c:v libvpx -pix_fmt yuva420p -auto-alt-ref 0 out.webm\n",
    "```\n",
    "\n",
    "#### Extract alpha channel from `.webm`\n",
    "\n",
    "```shell\n",
    "ffmpeg -vcodec libvpx -i in.webm -vf alphaextract -y out.mp4\n",
    "```\n",
    "\n",
    "\n",
    "#### Extract alpha channel from `.mov`\n",
    "\n",
    "```shell\n",
    "ffmpeg -i in.mov -vf alphaextract,format=yuv420p out.mp4\n",
    "```\n",
    "\n",
    "#### Compress resulting video\n",
    "```shell\n",
    "ffmpeg -i out.mp4 -vcodec h264 -b:v 1000k -acodec mp2 compressed_out.mp4 -y\n",
    "```\n",
    "\n",
    "#### Get first `n` frames\n",
    "```shell\n",
    "ffmpeg -i in.mp4 -frames:v 249 -c copy out.mp4\n",
    "```\n",
    "\n",
    "#### Cut video from `ss` till `t`\n",
    "```shell\n",
    "ffmpeg -ss 00:00:8.25 -i in.mp4 -t 00:00:8.25 out.mp4                                                               \n",
    "```\n",
    "\n",
    "#### Merge video with alpha channel in `.mov` file\n",
    "```shell\n",
    "ffmpeg -i in.mp4 -i alpha_in.mp4 -filter_complex [0][1]alphamerge -c:v qtrle out.mov\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
